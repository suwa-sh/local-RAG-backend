# =====================================
# 環境変数設定例
# =====================================
# このファイルを .env にコピーして使用してください
# cp .env.example .env

# Neo4j データベース設定（必須）
NEO4J_URL=bolt://localhost:7687

NEO4J_USER=neo4j

NEO4J_PASSWORD=password

# LLM API設定（必須）
# 推奨: OpenAI API直接接続（最高性能・最安定）
LLM_MODEL_URL=https://api.openai.com/v1

LLM_MODEL_KEY=your_openai_api_key_here

LLM_MODEL_NAME=gpt-4o-mini

# Rerankモデル（small_model用、省略時はLLM_MODEL_NAMEと同じ）
# より軽量で安価なモデルを指定して高速化・コスト削減
RERANK_MODEL_NAME=gpt-4.1-nano

# 注意: 以下の設定は実測で問題が確認されています
# LLM_MODEL_URL=http://localhost:4000/v1     # claude-code-server（遅延大）
# LLM_MODEL_URL=http://localhost:11434/v1    # ollama LLM（エラー頻発）
# LLM_MODEL_URL=https://openrouter.ai/api/v1 # rate limit問題

# 埋め込みモデル API設定（必須）
EMBEDDING_MODEL_URL=http://localhost:11434/v1

EMBEDDING_MODEL_KEY=dummy

EMBEDDING_MODEL_NAME=kun432/cl-nagoya-ruri-large:latest

# チャンク分割設定（オプション）
# 以下の設定は省略可能です。省略した場合はデフォルト値が使用されます。

# チャンクの最大文字数（デフォルト: 2000）
CHUNK_SIZE_MAX=2000

# チャンクの最小文字数（デフォルト: 200）
CHUNK_SIZE_MIN=200

# チャンクのオーバーラップ（デフォルト: 0）
CHUNK_OVERLAP=0
