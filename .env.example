# =====================================
# 環境変数設定例
# =====================================
# このファイルを .env にコピーして使用してください
# cp .env.example .env

# Neo4j データベース設定（必須）
NEO4J_URI=bolt://localhost:7687

NEO4J_USER=neo4j

NEO4J_PASSWORD=password

# LLM API設定（必須）
# 推奨: OpenAI API直接接続（最高性能・最安定）
LLM_MODEL_URL=https://api.openai.com/v1

LLM_MODEL_KEY=your_openai_api_key_here

LLM_MODEL_NAME=gpt-4o-mini

# Rerankモデル（省略時はLLM_MODEL_NAMEと同じ）
RERANK_MODEL_NAME=gpt-4.1-nano

# 埋め込みモデル API設定（必須）
EMBEDDING_MODEL_URL=http://host.docker.internal:11434/v1

EMBEDDING_MODEL_KEY=dummy

EMBEDDING_MODEL_NAME=kun432/cl-nagoya-ruri-large:latest

# テナント識別子設定（必須）
GROUP_ID=default

# チャンク分割設定（オプション）
# 以下の設定は省略可能です。省略した場合はデフォルト値が使用されます。

# チャンクの最大文字数（デフォルト: 2000）
CHUNK_SIZE_MAX=2000

# チャンクの最小文字数（デフォルト: 200）
CHUNK_SIZE_MIN=200

# チャンクのオーバーラップ（デフォルト: 0）
CHUNK_OVERLAP=0

# ログレベル設定（オプション）
# INFO: 本番運用向け（推奨）- 重要な情報のみ
# DEBUG: パフォーマンス分析向け - 詳細な統計情報を出力
LOG_LEVEL=INFO

# 並列処理設定（オプション）
# チャンク処理の並列ワーカー数（デフォルト: 3）
INGEST_CHUNK_WORKERS=3

# 登録処理の並列ワーカー数（デフォルト: 2）
INGEST_REGISTER_WORKERS=2
