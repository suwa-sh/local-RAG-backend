"""GraphitiEpisodeRepository - é«˜é€ŸåŒ–ã®ãŸã‚ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¸¦åˆ—ä¿å­˜"""

import asyncio
import logging
import threading
from typing import List, Dict
from graphiti_core.graphiti import Graphiti, EpisodeType
from graphiti_core.llm_client import OpenAIClient, LLMConfig
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.llm_client.errors import RateLimitError
from src.domain.episode import Episode
from src.adapter.entity_cache import get_entity_cache
from src.adapter.rate_limit_retry_handler import RateLimitRetryHandler
from src.adapter.rate_limit_coordinator import get_rate_limit_coordinator


class GraphitiEpisodeRepository:
    """Graphitiã‚’ä½¿ç”¨ã—ãŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜ãƒªãƒã‚¸ãƒˆãƒªï¼ˆä¸¦åˆ—å‡¦ç†å¯¾å¿œï¼‰"""

    def __init__(
        self,
        neo4j_uri: str,
        neo4j_user: str,
        neo4j_password: str,
        llm_api_key: str,
        llm_base_url: str,
        llm_model: str,
        rerank_model: str,
        embedding_api_key: str,
        embedding_base_url: str,
        embedding_model: str,
    ) -> None:
        """
        GraphitiEpisodeRepositoryã‚’åˆæœŸåŒ–ã™ã‚‹

        Args:
            neo4j_uri: Neo4jã®URI
            neo4j_user: Neo4jã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å
            neo4j_password: Neo4jã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
            llm_api_key: LLM APIã‚­ãƒ¼
            llm_base_url: LLM APIã®ãƒ™ãƒ¼ã‚¹URL
            llm_model: ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«
            rerank_model: ä½¿ç”¨ã™ã‚‹rerankãƒ¢ãƒ‡ãƒ«ï¼ˆsmall_modelç”¨ï¼‰
            embedding_api_key: åŸ‹ã‚è¾¼ã¿APIã‚­ãƒ¼
            embedding_base_url: åŸ‹ã‚è¾¼ã¿APIã®ãƒ™ãƒ¼ã‚¹URL
            embedding_model: ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
        """
        # LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
        llm_config = LLMConfig(
            api_key=llm_api_key,
            base_url=llm_base_url,
            model=llm_model,
            small_model=rerank_model,
        )
        llm_client = OpenAIClient(config=llm_config)

        # åŸ‹ã‚è¾¼ã¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
        embedder_config = OpenAIEmbedderConfig(
            api_key=embedding_api_key,
            base_url=embedding_base_url,
            embedding_model=embedding_model,
        )
        embedder = OpenAIEmbedder(config=embedder_config)

        # Graphitiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.client = Graphiti(
            uri=neo4j_uri,
            user=neo4j_user,
            password=neo4j_password,
            llm_client=llm_client,
            embedder=embedder,
        )

        # ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
        self._logger = logging.getLogger(__name__)

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆæœŸåŒ–
        self.entity_cache = get_entity_cache()

        # Rate limitãƒªãƒˆãƒ©ã‚¤ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®åˆæœŸåŒ–
        self.retry_handler = RateLimitRetryHandler(
            logger=self._logger,
        )

        # Rate limitã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        self.rate_limit_coordinator = get_rate_limit_coordinator()

        self._logger.info(f"ğŸ”— Graphitiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº† - Neo4j: {neo4j_uri}")
        self._logger.info("ğŸ“‹ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–å®Œäº†")
        self._logger.info("ğŸ”„ Rate Limitã‚¹ãƒ¬ãƒƒãƒ‰åŒæœŸã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†")

    async def initialize(self) -> None:
        """
        Graphitiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®éåŒæœŸåˆæœŸåŒ–
        ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨åˆ¶ç´„ã‚’æ§‹ç¯‰ã™ã‚‹
        """
        try:
            await self.client.build_indices_and_constraints()
            self._logger.info("ğŸ—ï¸ Graphiti ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨åˆ¶ç´„ã®æ§‹ç¯‰å®Œäº†")
        except Exception as e:
            self._logger.error(f"âŒ Graphiti ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    async def save(self, episode: Episode) -> None:
        """
        å˜ä¸€ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ä¿å­˜ã™ã‚‹

        Args:
            episode: ä¿å­˜ã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰

        Raises:
            Exception: Graphitiã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
        """
        # ã‚¹ãƒ¬ãƒƒãƒ‰IDã‚’å–å¾—
        thread_id = str(threading.current_thread().ident or "unknown")

        # Rate LimitçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ã«å¿œã˜ã¦å¾…æ©Ÿ
        await self.rate_limit_coordinator.check_and_wait_if_needed(thread_id)

        # episode_typeã‚’å¯¾å¿œã™ã‚‹EpisodeTypeã«å¤‰æ›
        episode_type_mapping = {
            "text": EpisodeType.text,
            "json": EpisodeType.json,
            "message": EpisodeType.message,
        }

        source_type = episode_type_mapping.get(episode.episode_type, EpisodeType.text)

        self._logger.debug(f"ğŸ’¾ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜é–‹å§‹: {episode.name}")
        self._logger.debug(f"  - group_id: {episode.group_id.value}")
        self._logger.debug(f"  - episode_type: {episode.episode_type} -> {source_type}")
        self._logger.debug(f"  - body_length: {len(episode.body)}")

        # ã‚¨ãƒ©ãƒ¼åˆ¥ã®ãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        rate_limit_attempts = 0
        index_error_attempts = 0

        while True:
            try:
                await self.client.add_episode(
                    name=episode.name,
                    episode_body=episode.body,
                    source_description=episode.source_description,
                    reference_time=episode.reference_time,
                    source=source_type,
                    group_id=episode.group_id.value,
                )
                self._logger.debug(f"âœ… ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜å®Œäº†: {episode.name}")
                return
            except RateLimitError as e:
                if rate_limit_attempts < self.retry_handler.max_retries:
                    retry_after = self.retry_handler.extract_retry_after_time(e)
                    wait_time = (
                        retry_after
                        if retry_after
                        else self.retry_handler.default_wait_time
                    )

                    # Rate Limitã‚’å…¨ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€šçŸ¥
                    await self.rate_limit_coordinator.notify_rate_limit(
                        thread_id, wait_time, str(e)
                    )

                    # ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ãŒå®Ÿéš›ã«å¾…æ©Ÿ
                    await self.rate_limit_coordinator.wait_for_rate_limit_completion(
                        thread_id
                    )

                    rate_limit_attempts += 1
                else:
                    self._logger.error(
                        f"âŒ Rate limit error after {self.retry_handler.max_retries} retries: {episode.name}"
                    )
                    raise
            except IndexError as e:
                if "list index out of range" in str(e):
                    if index_error_attempts < self.retry_handler.max_retries:
                        # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆ1ç§’ã€2ç§’ã€4ç§’...ï¼‰- graphitiã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ç«¶åˆã‚¨ãƒ©ãƒ¼ç”¨
                        wait_time = 2**index_error_attempts
                        self._logger.warning(
                            f"âš ï¸ Graphitiã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ç«¶åˆã‚¨ãƒ©ãƒ¼ã€‚{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ "
                            f"(index error attempt {index_error_attempts + 1}/{self.retry_handler.max_retries}): {episode.name}"
                        )
                        await asyncio.sleep(wait_time)
                        index_error_attempts += 1
                    else:
                        self._logger.error(
                            f"âŒ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ç«¶åˆã‚¨ãƒ©ãƒ¼ï¼ˆæœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°è¶…éï¼‰: {episode.name}"
                        )
                        raise
                else:
                    self._logger.error(f"âŒ IndexErrorï¼ˆéç«¶åˆï¼‰: {episode.name} - {e}")
                    raise
            except Exception as e:
                self._logger.error(f"âŒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜å¤±æ•—: {episode.name} - {e}")
                raise
