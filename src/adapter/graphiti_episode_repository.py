"""GraphitiEpisodeRepository - é«˜é€ŸåŒ–ã®ãŸã‚ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¸¦åˆ—ä¿å­˜"""

import asyncio
import logging
from typing import List, Dict
from graphiti_core.graphiti import Graphiti, EpisodeType
from graphiti_core.llm_client import OpenAIClient, LLMConfig
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.llm_client.errors import RateLimitError
from src.domain.episode import Episode
from src.adapter.entity_cache import get_entity_cache
from src.adapter.rate_limit_retry_handler import RateLimitRetryHandler


class GraphitiEpisodeRepository:
    """Graphitiã‚’ä½¿ç”¨ã—ãŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜ãƒªãƒã‚¸ãƒˆãƒªï¼ˆä¸¦åˆ—å‡¦ç†å¯¾å¿œï¼‰"""

    def __init__(
        self,
        neo4j_uri: str,
        neo4j_user: str,
        neo4j_password: str,
        llm_api_key: str,
        llm_base_url: str,
        llm_model: str,
        rerank_model: str,
        embedding_api_key: str,
        embedding_base_url: str,
        embedding_model: str,
        rate_limit_max_retries: int = 3,
        rate_limit_default_wait_time: int = 121,
    ) -> None:
        """
        GraphitiEpisodeRepositoryã‚’åˆæœŸåŒ–ã™ã‚‹

        Args:
            neo4j_uri: Neo4jã®URI
            neo4j_user: Neo4jã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å
            neo4j_password: Neo4jã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
            llm_api_key: LLM APIã‚­ãƒ¼
            llm_base_url: LLM APIã®ãƒ™ãƒ¼ã‚¹URL
            llm_model: ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«
            rerank_model: ä½¿ç”¨ã™ã‚‹rerankãƒ¢ãƒ‡ãƒ«ï¼ˆsmall_modelç”¨ï¼‰
            embedding_api_key: åŸ‹ã‚è¾¼ã¿APIã‚­ãƒ¼
            embedding_base_url: åŸ‹ã‚è¾¼ã¿APIã®ãƒ™ãƒ¼ã‚¹URL
            embedding_model: ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
        """
        # LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
        llm_config = LLMConfig(
            api_key=llm_api_key,
            base_url=llm_base_url,
            model=llm_model,
            small_model=rerank_model,
        )
        llm_client = OpenAIClient(config=llm_config)

        # åŸ‹ã‚è¾¼ã¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
        embedder_config = OpenAIEmbedderConfig(
            api_key=embedding_api_key,
            base_url=embedding_base_url,
            embedding_model=embedding_model,
        )
        embedder = OpenAIEmbedder(config=embedder_config)

        # Graphitiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.client = Graphiti(
            uri=neo4j_uri,
            user=neo4j_user,
            password=neo4j_password,
            llm_client=llm_client,
            embedder=embedder,
        )

        # ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
        self._logger = logging.getLogger(__name__)

        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆæœŸåŒ–
        self.entity_cache = get_entity_cache()

        # Rate limitãƒªãƒˆãƒ©ã‚¤ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®åˆæœŸåŒ–
        self.retry_handler = RateLimitRetryHandler(
            max_retries=rate_limit_max_retries,
            default_wait_time=rate_limit_default_wait_time,
            logger=self._logger,
        )

        self._logger.info(f"ğŸ”— Graphitiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº† - Neo4j: {neo4j_uri}")
        self._logger.info("ğŸ“‹ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–å®Œäº†")

    async def save(self, episode: Episode) -> None:
        """
        å˜ä¸€ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ä¿å­˜ã™ã‚‹

        Args:
            episode: ä¿å­˜ã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰

        Raises:
            Exception: Graphitiã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
        """
        # episode_typeã‚’å¯¾å¿œã™ã‚‹EpisodeTypeã«å¤‰æ›
        episode_type_mapping = {
            "text": EpisodeType.text,
            "json": EpisodeType.json,
            "message": EpisodeType.message,
        }

        source_type = episode_type_mapping.get(episode.episode_type, EpisodeType.text)

        self._logger.debug(f"ğŸ’¾ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜é–‹å§‹: {episode.name}")
        self._logger.debug(f"  - group_id: {episode.group_id.value}")
        self._logger.debug(f"  - episode_type: {episode.episode_type} -> {source_type}")
        self._logger.debug(f"  - body_length: {len(episode.body)}")

        # Rate limitãƒªãƒˆãƒ©ã‚¤å‡¦ç†
        attempt = 0
        while attempt <= self.retry_handler.max_retries:
            try:
                await self.client.add_episode(
                    name=episode.name,
                    episode_body=episode.body,
                    source_description=episode.source_description,
                    reference_time=episode.reference_time,
                    source=source_type,
                    group_id=episode.group_id.value,
                )
                self._logger.debug(f"âœ… ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜å®Œäº†: {episode.name}")
                return
            except RateLimitError as e:
                if attempt < self.retry_handler.max_retries:
                    retry_after = self.retry_handler.extract_retry_after_time(e)
                    if retry_after:
                        self._logger.info(
                            f"ğŸ”„ Rate limit detected. Waiting {retry_after} seconds before retry "
                            f"(attempt {attempt + 1}/{self.retry_handler.max_retries})"
                        )
                        await asyncio.sleep(retry_after)
                    else:
                        self._logger.info(
                            f"ğŸ”„ Rate limit detected. Using default wait time "
                            f"({self.retry_handler.default_wait_time} seconds) before retry "
                            f"(attempt {attempt + 1}/{self.retry_handler.max_retries})"
                        )
                        await asyncio.sleep(self.retry_handler.default_wait_time)
                    attempt += 1
                else:
                    self._logger.error(
                        f"âŒ Rate limit error after {self.retry_handler.max_retries} retries: {episode.name}"
                    )
                    raise
            except Exception as e:
                self._logger.error(f"âŒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜å¤±æ•—: {episode.name} - {e}")
                raise

    async def save_batch(
        self, episodes: List[Episode], max_concurrent: int = 3
    ) -> None:
        """
        è¤‡æ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ä¸¦åˆ—ã§ä¸€æ‹¬ä¿å­˜ã™ã‚‹

        Args:
            episodes: ä¿å­˜ã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
            max_concurrent: æœ€å¤§åŒæ™‚å®Ÿè¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰

        Raises:
            Exception: Graphitiã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
        """
        if not episodes:
            self._logger.warning("âš ï¸ ä¿å­˜å¯¾è±¡ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        self._logger.info(f"ğŸ“¦ ä¸€æ‹¬ä¿å­˜é–‹å§‹ï¼ˆä¸¦åˆ—ï¼‰: {len(episodes)}ä»¶ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        episodes_by_file = self._group_episodes_by_file(episodes)

        # ã‚»ãƒãƒ•ã‚©ã§åŒæ™‚å®Ÿè¡Œæ•°ã‚’åˆ¶é™
        semaphore = asyncio.Semaphore(max_concurrent)

        async def save_with_semaphore(
            episode: Episode, file_path: str, index: int, total: int
        ):
            async with semaphore:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
                from src.adapter.logging_utils import current_file

                current_file.set(file_path)

                self._logger.debug(
                    f"ğŸ“ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä¿å­˜ä¸­ ({index}/{total}): {episode.name}"
                )
                await self.save(episode)

        # å…¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ä¿å­˜ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        tasks = []
        total_episodes = len(episodes)
        current_index = 0

        for file_path, file_episodes in episodes_by_file.items():
            self._logger.info(
                f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {file_path} ({len(file_episodes)}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰)"
            )

            for episode in file_episodes:
                current_index += 1
                task = save_with_semaphore(
                    episode, file_path, current_index, total_episodes
                )
                tasks.append(task)

        # å…¨ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ
        await asyncio.gather(*tasks)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›
        self.entity_cache.log_cache_stats()
        self._logger.info(f"âœ… ä¸€æ‹¬ä¿å­˜å®Œäº†ï¼ˆä¸¦åˆ—ï¼‰: {len(episodes)}ä»¶ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰")

    def _group_episodes_by_file(
        self, episodes: List[Episode]
    ) -> Dict[str, List[Episode]]:
        """
        ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹

        Args:
            episodes: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ

        Returns:
            Dict[str, List[Episode]]: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ã‚­ãƒ¼ã¨ã—ãŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ã‚°ãƒ«ãƒ¼ãƒ—
        """
        episodes_by_file = {}

        for episode in episodes:
            file_path = self._extract_file_path_from_source(episode.source_description)

            if file_path not in episodes_by_file:
                episodes_by_file[file_path] = []
            episodes_by_file[file_path].append(episode)

        return episodes_by_file

    def _extract_file_path_from_source(self, source_description: str) -> str:
        """
        source_descriptionã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŠ½å‡ºã™ã‚‹

        Args:
            source_description: ã‚½ãƒ¼ã‚¹èª¬æ˜æ–‡å­—åˆ—

        Returns:
            str: æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # "Source file: /path/to/file.ext" ã®å½¢å¼ã‹ã‚‰ãƒ‘ã‚¹ã‚’æŠ½å‡º
        if source_description.startswith("Source file: "):
            return source_description[13:]  # "Source file: " ã®æ–‡å­—æ•°åˆ†ã‚’ã‚¹ã‚­ãƒƒãƒ—
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: èª¬æ˜æ–‡å­—åˆ—å…¨ä½“ã‚’ä½¿ç”¨
            return source_description

    async def close(self) -> None:
        """
        Graphitiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é–‰ã˜ã‚‹
        """
        await self.client.close()
