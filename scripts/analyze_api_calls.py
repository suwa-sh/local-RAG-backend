#!/usr/bin/env python3
"""
APIå‘¼ã³å‡ºã—åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚LLMã¨Embeddingã®å‘¼ã³å‡ºã—å›æ•°ã¨å‡¦ç†æ™‚é–“ã‚’æŠ½å‡ºã™ã‚‹
"""

import re
import sys
from datetime import datetime
from collections import defaultdict


def parse_time(time_str):
    """æ™‚åˆ»æ–‡å­—åˆ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›"""
    try:
        # HH:MM:SSå½¢å¼
        time_obj = datetime.strptime(time_str, "%H:%M:%S")
        return time_obj
    except ValueError:
        return None


def analyze_log_file(log_file_path):
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã¦APIå‘¼ã³å‡ºã—çµ±è¨ˆã‚’ç”Ÿæˆ"""

    llm_requests = []
    embedding_requests = []

    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
    pending_llm = {}
    pending_embedding = {}

    try:
        with open(log_file_path, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                # æ™‚åˆ»ã‚’æŠ½å‡º
                time_match = re.match(r"^(\d{2}:\d{2}:\d{2})", line)
                if not time_match:
                    continue

                time_str = time_match.group(1)
                time_obj = parse_time(time_str)
                if not time_obj:
                    continue

                # ã‚¹ãƒ¬ãƒƒãƒ‰IDã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º [T123][filename]
                thread_match = re.search(r"\[T(\d+)\]\[([^\]]+)\]", line)
                thread_id = thread_match.group(1) if thread_match else "unknown"
                file_name = thread_match.group(2) if thread_match else "unknown"

                # LLM ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹
                if "Sending HTTP Request: POST" in line and "chat/completions" in line:
                    key = f"{thread_id}_{file_name}"
                    pending_llm[key] = {
                        "start_time": time_obj,
                        "line_num": line_num,
                        "thread_id": thread_id,
                        "file_name": file_name,
                    }

                # LLM ãƒ¬ã‚¹ãƒãƒ³ã‚¹
                elif "HTTP Response: POST" in line and "chat/completions" in line:
                    key = f"{thread_id}_{file_name}"
                    if key in pending_llm:
                        start_info = pending_llm.pop(key)
                        duration = (time_obj - start_info["start_time"]).total_seconds()
                        llm_requests.append(
                            {
                                "thread_id": thread_id,
                                "file_name": file_name,
                                "start_time": start_info["start_time"],
                                "end_time": time_obj,
                                "duration": duration,
                                "start_line": start_info["line_num"],
                                "end_line": line_num,
                            }
                        )

                # Embedding ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹
                elif "Sending HTTP Request: POST" in line and "embeddings" in line:
                    key = f"{thread_id}_{file_name}_{time_obj.timestamp()}"  # åŒæ™‚ä¸¦è¡Œã®ãŸã‚æ™‚åˆ»ã‚‚å«ã‚ã‚‹
                    pending_embedding[key] = {
                        "start_time": time_obj,
                        "line_num": line_num,
                        "thread_id": thread_id,
                        "file_name": file_name,
                    }

                # Embedding ãƒ¬ã‚¹ãƒãƒ³ã‚¹
                elif "HTTP Response: POST" in line and "embeddings" in line:
                    # æœ€ã‚‚è¿‘ã„é–‹å§‹æ™‚åˆ»ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ãƒãƒƒãƒãƒ³ã‚°
                    matching_key = None
                    min_diff = float("inf")

                    for key, start_info in pending_embedding.items():
                        if (
                            start_info["thread_id"] == thread_id
                            and start_info["file_name"] == file_name
                        ):
                            diff = abs(
                                (time_obj - start_info["start_time"]).total_seconds()
                            )
                            if diff < min_diff:
                                min_diff = diff
                                matching_key = key

                    if matching_key:
                        start_info = pending_embedding.pop(matching_key)
                        duration = (time_obj - start_info["start_time"]).total_seconds()
                        embedding_requests.append(
                            {
                                "thread_id": thread_id,
                                "file_name": file_name,
                                "start_time": start_info["start_time"],
                                "end_time": time_obj,
                                "duration": duration,
                                "start_line": start_info["line_num"],
                                "end_line": line_num,
                            }
                        )

    except FileNotFoundError:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {log_file_path}")
        return None
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return None

    return {
        "llm_requests": llm_requests,
        "embedding_requests": embedding_requests,
        "pending_llm": pending_llm,
        "pending_embedding": pending_embedding,
    }


def print_statistics(analysis_result):
    """çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›"""
    if not analysis_result:
        return

    llm_requests = analysis_result["llm_requests"]
    embedding_requests = analysis_result["embedding_requests"]

    print("=" * 80)
    print("APIå‘¼ã³å‡ºã—åˆ†æçµæœ")
    print("=" * 80)

    # LLMçµ±è¨ˆ
    print("\nğŸ¤– LLM APIå‘¼ã³å‡ºã— (chat/completions)")
    print(f"  ç·å‘¼ã³å‡ºã—å›æ•°: {len(llm_requests)}")

    if llm_requests:
        durations = [req["duration"] for req in llm_requests]
        avg_duration = sum(durations) / len(durations)
        max_duration = max(durations)
        min_duration = min(durations)
        total_duration = sum(durations)

        print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {avg_duration:.2f}ç§’")
        print(f"  æœ€å¤§å‡¦ç†æ™‚é–“: {max_duration:.2f}ç§’")
        print(f"  æœ€å°å‡¦ç†æ™‚é–“: {min_duration:.2f}ç§’")
        print(f"  ç·å‡¦ç†æ™‚é–“: {total_duration:.2f}ç§’")

        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥çµ±è¨ˆ
        file_stats = defaultdict(list)
        for req in llm_requests:
            file_stats[req["file_name"]].append(req["duration"])

        print("\n  ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥LLMå‘¼ã³å‡ºã—:")
        for file_name, durations in file_stats.items():
            count = len(durations)
            avg = sum(durations) / len(durations)
            total = sum(durations)
            print(f"    {file_name}: {count}å›, å¹³å‡{avg:.2f}ç§’, åˆè¨ˆ{total:.2f}ç§’")

    # Embeddingçµ±è¨ˆ
    print("\nğŸ”¤ Embedding APIå‘¼ã³å‡ºã— (/embeddings)")
    print(f"  ç·å‘¼ã³å‡ºã—å›æ•°: {len(embedding_requests)}")

    if embedding_requests:
        durations = [req["duration"] for req in embedding_requests]
        avg_duration = sum(durations) / len(durations)
        max_duration = max(durations)
        min_duration = min(durations)
        total_duration = sum(durations)

        print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {avg_duration:.2f}ç§’")
        print(f"  æœ€å¤§å‡¦ç†æ™‚é–“: {max_duration:.2f}ç§’")
        print(f"  æœ€å°å‡¦ç†æ™‚é–“: {min_duration:.2f}ç§’")
        print(f"  ç·å‡¦ç†æ™‚é–“: {total_duration:.2f}ç§’")

        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥çµ±è¨ˆ
        file_stats = defaultdict(list)
        for req in embedding_requests:
            file_stats[req["file_name"]].append(req["duration"])

        print("\n  ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥Embeddingå‘¼ã³å‡ºã—:")
        for file_name, durations in file_stats.items():
            count = len(durations)
            avg = sum(durations) / len(durations)
            total = sum(durations)
            print(f"    {file_name}: {count}å›, å¹³å‡{avg:.2f}ç§’, åˆè¨ˆ{total:.2f}ç§’")

    # æ¯”è¼ƒåˆ†æ
    print("\nğŸ“Š æ¯”è¼ƒåˆ†æ")
    if llm_requests and embedding_requests:
        llm_total = sum(req["duration"] for req in llm_requests)
        embedding_total = sum(req["duration"] for req in embedding_requests)
        grand_total = llm_total + embedding_total

        llm_percentage = (llm_total / grand_total) * 100
        embedding_percentage = (embedding_total / grand_total) * 100

        print(f"  LLMå‡¦ç†æ™‚é–“å‰²åˆ: {llm_percentage:.1f}% ({llm_total:.2f}ç§’)")
        print(
            f"  Embeddingå‡¦ç†æ™‚é–“å‰²åˆ: {embedding_percentage:.1f}% ({embedding_total:.2f}ç§’)"
        )
        print(f"  APIå‘¼ã³å‡ºã—ç·æ™‚é–“: {grand_total:.2f}ç§’")

    # æœªå®Œäº†ãƒªã‚¯ã‚¨ã‚¹ãƒˆè­¦å‘Š
    pending_llm = analysis_result["pending_llm"]
    pending_embedding = analysis_result["pending_embedding"]

    if pending_llm:
        print(f"\nâš ï¸  æœªå®Œäº†LLMãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {len(pending_llm)}ä»¶")
        for key, info in pending_llm.items():
            print(f"    {info['file_name']} (line {info['line_num']})")

    if pending_embedding:
        print(f"\nâš ï¸  æœªå®Œäº†Embeddingãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {len(pending_embedding)}ä»¶")
        for key, info in pending_embedding.items():
            print(f"    {info['file_name']} (line {info['line_num']})")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python analyze_api_calls.py <ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>")
        print("ä¾‹: python tmp/analyze_api_calls.py tmp/ingest-example-parallel.log")
        sys.exit(1)

    log_file_path = sys.argv[1]

    print(f"ğŸ“Š ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æä¸­: {log_file_path}")
    print("ã“ã‚Œã«ã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™...")

    analysis_result = analyze_log_file(log_file_path)
    print_statistics(analysis_result)


if __name__ == "__main__":
    main()
